{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    executable_path = {'executable_path':'C:/Users/serna/Desktop/chromedriver.exe'}\n",
    "    Browserbrowser = Browser('chrome', executable_path ='C:/Users/serna/Desktop/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    mars_data = {}\n",
    "    mars_data[\"news_data\"] = marsNewsData()\n",
    "    mars_data[\"featured_image_url\"] = marsFeaturedImageURL()\n",
    "    mars_data[\"mars_weather\"] = marsWeather()\n",
    "    mars_data[\"mars_facts\"] = marsFacts()\n",
    "    mars_data[\"mars_hemispheres\"] = marsHemisphereImageURLs()\n",
    "\n",
    "    # return mars_data dict\n",
    "    return mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'req' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aa194cb71bc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-f907a80816b8>\u001b[0m in \u001b[0;36mscrape\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmars_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmars_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"news_data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarsNewsData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmars_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"featured_image_url\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarsFeaturedImageURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmars_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mars_weather\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarsWeather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-aa194cb71bc7>\u001b[0m in \u001b[0;36mmarsNewsData\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbase_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://mars.nasa.gov/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnasa_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://mars.nasa.gov/news/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mresponse_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnasa_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'req' is not defined"
     ]
    }
   ],
   "source": [
    "def marsNewsData():\n",
    "    news_data = {}\n",
    "    paragraph_text = []\n",
    "\n",
    "    base_url = \"https://mars.nasa.gov/\"\n",
    "    nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "    response_1 = req.get(nasa_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    nasa_soup = bs(response_1.text, 'html.parser')\n",
    "    soup_div = nasa_soup.find(class_=\"slide\")\n",
    "    soup_news = soup_div.find_all('a')\n",
    "    news_title = soup_news[1].get_text().strip()\n",
    "    soup_p = soup_div.find_all('a', href=True)\n",
    "    soup_p_url = soup_p[0]['href']\n",
    "    paragraph_url = base_url + soup_p_url\n",
    "    response_2 = req.get(paragraph_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    para_soup = bs(response_2.text, \"html.parser\")\n",
    "    ww_paragraphs = para_soup.find(class_='wysiwyg_content')\n",
    "    paragraphs = ww_paragraphs.find_all('p')\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        clean_paragraph = paragraph.get_text().strip()\n",
    "        paragraph_text.append(clean_paragraph)\n",
    "\n",
    "    news_data[\"news_title\"] = news_title\n",
    "    news_data[\"paragraph_text_1\"] = paragraph_text[0]\n",
    "    news_data[\"paragraph_text_2\"] = paragraph_text[1]\n",
    "\n",
    "    return news_data\n",
    "# --------------------------------------------------------------------------\n",
    "# JPL Mars Space Images - Visit the url for JPL's Featured Space Image.\n",
    "# Use splinter to navigate the site and find the image url for the current\n",
    "# Featured Mars Image and assign the url string to a variable called\n",
    "# featured_image_url.\n",
    "# --------------------------------------------------------------------------\n",
    "def marsFeaturedImageURL():\n",
    "    \"\"\" Function: Mars featured image data scraping functionality\n",
    "        Scrapes JPL news site @ jpl_url below\n",
    "        Parameters: None\n",
    "        Returns: featured_image_url string \"\"\"\n",
    "\n",
    "    browser = initBrowser()\n",
    "\n",
    "    jpl_fullsize_url = 'https://photojournal.jpl.nasa.gov/jpeg/'\n",
    "    jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(jpl_url)\n",
    "    time.sleep(5)\n",
    "    jpl_html = browser.html\n",
    "    jpl_soup = bs(jpl_html, 'html.parser')\n",
    "    time.sleep(5)\n",
    "\n",
    "    featured_image_list = []\n",
    "\n",
    "    for image in jpl_soup.find_all('div',class_=\"img\"):\n",
    "        featured_image_list.append(image.find('img').get('src'))\n",
    "\n",
    "    feature_image = featured_image_list[0]\n",
    "    temp_list_1 = feature_image.split('-')\n",
    "    temp_list_2 = temp_list_1[0].split('/')\n",
    "    featured_image_url = jpl_fullsize_url + temp_list_2[-1] + '.jpg'\n",
    "\n",
    "    closeBrowser(browser)\n",
    "\n",
    "    return featured_image_url\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Mars Weather - Visit the Mars Weather twitter account and scrape the\n",
    "# latest Mars weather tweet from the page. Save the tweet text for the\n",
    "# weather report as a variable called mars_weather\n",
    "# --------------------------------------------------------------------------\n",
    "def marsWeather():\n",
    "    \"\"\" Function: Mars twitter weather data scraping functionality\n",
    "        Scrapes Twitter for weather news @ tweet_url below\n",
    "        Parameters: None\n",
    "        Returns: mars_weather string \"\"\"\n",
    "\n",
    "    browser = initBrowser()\n",
    "\n",
    "    tweet_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    browser.visit(tweet_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    tweet_html = browser.html\n",
    "    tweet_soup = bs(tweet_html, 'html.parser')\n",
    "    time.sleep(5)\n",
    "\n",
    "    weather_info_list = []\n",
    "\n",
    "    for weather_info in tweet_soup.find_all('p',class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\"):\n",
    "        weather_info_list.append(weather_info.text.strip())\n",
    "\n",
    "    for value in reversed(weather_info_list):\n",
    "        if value[:3]=='Sol':\n",
    "            mars_weather = value\n",
    "\n",
    "    closeBrowser(browser)\n",
    "\n",
    "    return mars_weather\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Mars Facts - Visit the Mars Facts webpage here and use Pandas to scrape\n",
    "# the table containing facts about the planet including Diameter, Mass, etc.\n",
    "# --------------------------------------------------------------------------\n",
    "def marsFacts():\n",
    "    \"\"\" Function: Mars facts data scraping functionality\n",
    "        Scrapes Space-Facts site @ facts_url below\n",
    "        Parameters: None\n",
    "        Returns facts_table string (HTML) \"\"\"\n",
    "\n",
    "    facts_url = 'https://space-facts.com/mars/'\n",
    "    fact_list = pd.read_html(facts_url)\n",
    "    time.sleep(5)\n",
    "    facts_df = fact_list[0]\n",
    "    facts_table = facts_df.to_html(header=False, index=False)\n",
    "\n",
    "    return facts_table\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Mars Hemisperes - Visit the USGS Astrogeology site to obtain\n",
    "# high resolution images for each of Mars' hemispheres.\n",
    "# --------------------------------------------------------------------------\n",
    "def marsHemisphereImageURLs():\n",
    "    \"\"\" Function: Mars hemispheres image data scraping functionality\n",
    "        Scrapes USGS site @ usgs_url below\n",
    "        Parameters: None\n",
    "        Returns: hemisphere_image_urls list \"\"\"\n",
    "\n",
    "    browser = initBrowser()\n",
    "\n",
    "    usgs_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(usgs_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    usgs_html = browser.html\n",
    "    usgs_soup = bs(usgs_html, 'html.parser')\n",
    "    time.sleep(5)\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "\n",
    "    products = usgs_soup.find('div', class_='result-list')\n",
    "    time.sleep(5)\n",
    "    hemispheres = products.find_all('div', class_='item')\n",
    "    time.sleep(5)\n",
    "\n",
    "    for hemisphere in hemispheres:\n",
    "        title = hemisphere.find('div', class_='description')\n",
    "\n",
    "        title_text = title.a.text\n",
    "        title_text = title_text.replace(' Enhanced', '')\n",
    "        browser.click_link_by_partial_text(title_text)\n",
    "\n",
    "        usgs_html = browser.html\n",
    "        usgs_soup = bs(usgs_html, 'html.parser')\n",
    "\n",
    "        image = usgs_soup.find('div', class_='downloads').find('ul').find('li')\n",
    "        img_url = image.a['href']\n",
    "\n",
    "        hemisphere_image_urls.append({'title': title_text, 'img_url': img_url})\n",
    "\n",
    "        browser.click_link_by_partial_text('Back')\n",
    "\n",
    "    closeBrowser(browser)\n",
    "\n",
    "    return hemisphere_image_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(scrape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
